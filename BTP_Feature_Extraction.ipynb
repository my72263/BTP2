{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-5EWZFSLZmI",
        "outputId": "13f961cb-79e6-4298-e167-c685cca1d410"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting medmnist\n",
            "  Downloading medmnist-2.1.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from medmnist) (1.3.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from medmnist) (7.1.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from medmnist) (0.18.3)\n",
            "Collecting fire\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from medmnist) (1.21.6)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from medmnist) (0.13.1+cu113)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from medmnist) (1.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from medmnist) (4.64.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from medmnist) (1.12.1+cu113)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire->medmnist) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire->medmnist) (2.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->medmnist) (2022.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->medmnist) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->medmnist) (2.6.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->medmnist) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->medmnist) (2.9.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->medmnist) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->medmnist) (1.7.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->medmnist) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->medmnist) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->medmnist) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->medmnist) (4.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->medmnist) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->medmnist) (3.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->medmnist) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->medmnist) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->medmnist) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->medmnist) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->medmnist) (2.10)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115943 sha256=8f86e1f7f7d87f0c383415338abd2bbb85b42163981f62252daa84789c686418\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
            "Successfully built fire\n",
            "Installing collected packages: fire, medmnist\n",
            "Successfully installed fire-0.4.0 medmnist-2.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install medmnist --user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoxf-r2i6wqt"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqvIoXZ_bfru"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 20\n",
        "BATCH_SIZE = 128\n",
        "lr = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_vp7DQwFP8J",
        "outputId": "3088a3e5-032d-4524-df95-b59991be86ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'MD5': 'a8b06965200029087d5bd730944a56c1',\n",
            " 'description': 'The PathMNIST is based on a prior study for predicting '\n",
            "                'survival from colorectal cancer histology slides, providing a '\n",
            "                'dataset (NCT-CRC-HE-100K) of 100,000 non-overlapping image '\n",
            "                'patches from hematoxylin & eosin stained histological images, '\n",
            "                'and a test dataset (CRC-VAL-HE-7K) of 7,180 image patches '\n",
            "                'from a different clinical center. The dataset is comprised of '\n",
            "                '9 types of tissues, resulting in a multi-class classification '\n",
            "                'task. We resize the source images of 3×224×224 into 3×28×28, '\n",
            "                'and split NCT-CRC-HE-100K into training and validation set '\n",
            "                'with a ratio of 9:1. The CRC-VAL-HE-7K is treated as the test '\n",
            "                'set.',\n",
            " 'label': {'0': 'adipose',\n",
            "           '1': 'background',\n",
            "           '2': 'debris',\n",
            "           '3': 'lymphocytes',\n",
            "           '4': 'mucus',\n",
            "           '5': 'smooth muscle',\n",
            "           '6': 'normal colon mucosa',\n",
            "           '7': 'cancer-associated stroma',\n",
            "           '8': 'colorectal adenocarcinoma epithelium'},\n",
            " 'license': 'CC BY 4.0',\n",
            " 'n_channels': 3,\n",
            " 'n_samples': {'test': 7180, 'train': 89996, 'val': 10004},\n",
            " 'python_class': 'PathMNIST',\n",
            " 'task': 'multi-class',\n",
            " 'url': 'https://zenodo.org/record/6496656/files/pathmnist.npz?download=1'}\n"
          ]
        }
      ],
      "source": [
        "!python -m medmnist info --flag=pathmnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtne9UkN6wq9"
      },
      "outputs": [],
      "source": [
        "data_flag = 'pathmnist'\n",
        "download = True\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "231cb88ce25a45089090375095790f16",
            "171600feb07640718086820482ebda76",
            "d2f05dfde85d42adb7d8e4edfee145d1",
            "6ecafece7c4748ea97d2a4ffea9cb21e",
            "f535159a00c3494aab4989eebb894024",
            "05c33a505bce400182cac16b0ea25d41",
            "a07222e0a31a44818196ea256ef67338",
            "bd846d4d74d04dbaafa5f3f7bbbebd06",
            "5ed160e8b9a542e2b01f11ce348ff649",
            "c00be766afe04ca495ddbce49132ff62",
            "37f0bea3477141b892a1d58bd357b43a"
          ]
        },
        "id": "jrPV8PaN6wq_",
        "outputId": "559b11b8-97ab-4703-8c78-1af99bc4746e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://zenodo.org/record/6496656/files/pathmnist.npz?download=1 to /root/.medmnist/pathmnist.npz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/205615438 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "231cb88ce25a45089090375095790f16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/pathmnist.npz\n",
            "Using downloaded and verified file: /root/.medmnist/pathmnist.npz\n"
          ]
        }
      ],
      "source": [
        "# preprocessing\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# load the data\n",
        "train_dataset = DataClass(split='train', transform=data_transform, download=download)\n",
        "test_dataset = DataClass(split='test', transform=data_transform, download=download)\n",
        "\n",
        "pil_dataset = DataClass(split='train', download=download)\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4N6yk5_6wrB",
        "outputId": "07fad27a-eee0-479a-e3e8-aac63843575a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset PathMNIST (pathmnist)\n",
            "    Number of datapoints: 89996\n",
            "    Root location: /root/.medmnist\n",
            "    Split: train\n",
            "    Task: multi-class\n",
            "    Number of channels: 3\n",
            "    Meaning of labels: {'0': 'adipose', '1': 'background', '2': 'debris', '3': 'lymphocytes', '4': 'mucus', '5': 'smooth muscle', '6': 'normal colon mucosa', '7': 'cancer-associated stroma', '8': 'colorectal adenocarcinoma epithelium'}\n",
            "    Number of samples: {'train': 89996, 'val': 10004, 'test': 7180}\n",
            "    Description: The PathMNIST is based on a prior study for predicting survival from colorectal cancer histology slides, providing a dataset (NCT-CRC-HE-100K) of 100,000 non-overlapping image patches from hematoxylin & eosin stained histological images, and a test dataset (CRC-VAL-HE-7K) of 7,180 image patches from a different clinical center. The dataset is comprised of 9 types of tissues, resulting in a multi-class classification task. We resize the source images of 3×224×224 into 3×28×28, and split NCT-CRC-HE-100K into training and validation set with a ratio of 9:1. The CRC-VAL-HE-7K is treated as the test set.\n",
            "    License: CC BY 4.0\n",
            "===================\n",
            "Dataset PathMNIST (pathmnist)\n",
            "    Number of datapoints: 7180\n",
            "    Root location: /root/.medmnist\n",
            "    Split: test\n",
            "    Task: multi-class\n",
            "    Number of channels: 3\n",
            "    Meaning of labels: {'0': 'adipose', '1': 'background', '2': 'debris', '3': 'lymphocytes', '4': 'mucus', '5': 'smooth muscle', '6': 'normal colon mucosa', '7': 'cancer-associated stroma', '8': 'colorectal adenocarcinoma epithelium'}\n",
            "    Number of samples: {'train': 89996, 'val': 10004, 'test': 7180}\n",
            "    Description: The PathMNIST is based on a prior study for predicting survival from colorectal cancer histology slides, providing a dataset (NCT-CRC-HE-100K) of 100,000 non-overlapping image patches from hematoxylin & eosin stained histological images, and a test dataset (CRC-VAL-HE-7K) of 7,180 image patches from a different clinical center. The dataset is comprised of 9 types of tissues, resulting in a multi-class classification task. We resize the source images of 3×224×224 into 3×28×28, and split NCT-CRC-HE-100K into training and validation set with a ratio of 9:1. The CRC-VAL-HE-7K is treated as the test set.\n",
            "    License: CC BY 4.0\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset)\n",
        "print(\"===================\")\n",
        "print(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2bWcD6S6wrE",
        "outputId": "d53b0b02-1012-4e77-95b5-db228d01e884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 26, 26]             448\n",
            "       BatchNorm2d-2           [-1, 16, 26, 26]              32\n",
            "              ReLU-3           [-1, 16, 26, 26]               0\n",
            "            Conv2d-4           [-1, 16, 24, 24]           2,320\n",
            "       BatchNorm2d-5           [-1, 16, 24, 24]              32\n",
            "              ReLU-6           [-1, 16, 24, 24]               0\n",
            "            Conv2d-7           [-1, 64, 22, 22]           9,280\n",
            "       BatchNorm2d-8           [-1, 64, 22, 22]             128\n",
            "              ReLU-9           [-1, 64, 22, 22]               0\n",
            "           Conv2d-10           [-1, 64, 20, 20]          36,928\n",
            "      BatchNorm2d-11           [-1, 64, 20, 20]             128\n",
            "             ReLU-12           [-1, 64, 20, 20]               0\n",
            "           Conv2d-13           [-1, 64, 18, 18]          36,928\n",
            "      BatchNorm2d-14           [-1, 64, 18, 18]             128\n",
            "             ReLU-15           [-1, 64, 18, 18]               0\n",
            "           Linear-16                    [-1, 9]         186,633\n",
            "          Softmax-17                    [-1, 9]               0\n",
            "================================================================\n",
            "Total params: 272,985\n",
            "Trainable params: 272,985\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.23\n",
            "Params size (MB): 1.04\n",
            "Estimated Total Size (MB): 3.28\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# define a simple CNN model\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 16, kernel_size=3),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 16, kernel_size=3),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(16, 64, kernel_size=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU())\n",
        "        \n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(20736, num_classes),\n",
        "            nn.Softmax(-1))\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer5(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "model = Net(in_channels=n_channels, num_classes=n_classes)\n",
        "    \n",
        "# define loss function and optimizer\n",
        "if task == \"multi-label, binary-class\":\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "else:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "!pip install torchsummary\n",
        "\n",
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "\n",
        "summary(model, (n_channels, 28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBd9dwFQ6wrG",
        "outputId": "aa01023c-0e11-4f33-a1d5-deaec2dc81fd",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 704/704 [00:34<00:00, 20.58it/s]\n",
            "100%|██████████| 704/704 [00:26<00:00, 26.65it/s]\n",
            "100%|██████████| 704/704 [00:26<00:00, 26.52it/s]\n",
            "100%|██████████| 704/704 [00:26<00:00, 26.46it/s]\n",
            "100%|██████████| 704/704 [00:26<00:00, 26.47it/s]\n",
            "100%|██████████| 704/704 [00:26<00:00, 26.90it/s]\n",
            "100%|██████████| 704/704 [00:26<00:00, 26.34it/s]\n",
            "100%|██████████| 704/704 [00:26<00:00, 26.51it/s]\n",
            "100%|██████████| 704/704 [00:25<00:00, 27.18it/s]\n",
            "100%|██████████| 704/704 [00:26<00:00, 26.42it/s]\n",
            "100%|██████████| 704/704 [00:26<00:00, 27.07it/s]\n",
            "100%|██████████| 704/704 [00:26<00:00, 26.24it/s]\n",
            "100%|██████████| 704/704 [00:26<00:00, 26.36it/s]\n",
            "100%|██████████| 704/704 [00:26<00:00, 26.23it/s]\n",
            "100%|██████████| 704/704 [00:26<00:00, 26.84it/s]\n",
            "100%|██████████| 704/704 [00:26<00:00, 26.67it/s]\n",
            "100%|██████████| 704/704 [00:26<00:00, 26.25it/s]\n",
            "100%|██████████| 704/704 [00:26<00:00, 26.58it/s]\n",
            "100%|██████████| 704/704 [00:26<00:00, 26.21it/s]\n",
            "100%|██████████| 704/704 [00:26<00:00, 26.95it/s]\n"
          ]
        }
      ],
      "source": [
        "# train\n",
        "\n",
        "losses = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "    for inputs, targets in tqdm(train_loader) :\n",
        "        # forward + backward + optimize\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        inputs1 = inputs.to(device)\n",
        "        targets1 = targets.to(device)\n",
        "        outputs = model(inputs1)\n",
        "        \n",
        "        if task == 'multi-label, binary-class':\n",
        "            targets2 = targets1.to(torch.float32)\n",
        "            loss = criterion(outputs, targets2)\n",
        "        else:\n",
        "            targets2 = targets1.squeeze().long()\n",
        "            loss = criterion(outputs, targets2)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0) \n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    losses.append(epoch_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iawHqM7e6wrH",
        "outputId": "eda0521d-067d-45a9-867a-143b8bd29753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Evaluating ...\n",
            "train  acc: 0.971  auc:0.832\n",
            "test  acc: 0.863  auc:0.695\n"
          ]
        }
      ],
      "source": [
        "# evaluation\n",
        "\n",
        "def test(split):\n",
        "    model.eval()\n",
        "    y_true = torch.tensor([])\n",
        "    y_score = torch.tensor([])\n",
        "    \n",
        "    data_loader = train_loader_at_eval if split == 'train' else test_loader\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader:\n",
        "            outputs = model(inputs.to(device))\n",
        "\n",
        "            if task == 'multi-label, binary-class':\n",
        "                targets = targets.to(torch.float32)\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "            else:\n",
        "                targets = targets.squeeze().long()\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "                targets = targets.float().resize_(len(targets), 1)\n",
        "\n",
        "            y_true = torch.cat((y_true.to(device), targets.to(device)), 0)\n",
        "            y_score = torch.cat((y_score.to(device), outputs.to(device)), 0)\n",
        "        y_true = y_true.cpu()\n",
        "        y_true = y_true.numpy()\n",
        "        y_score = y_score.cpu()\n",
        "        y_score = y_score.detach().numpy()\n",
        "        \n",
        "        evaluator = Evaluator(data_flag, split)\n",
        "        metrics = evaluator.evaluate(y_score)\n",
        "    \n",
        "        print('%s  acc: %.3f  auc:%.3f' % (split, *metrics))\n",
        "\n",
        "        \n",
        "print('==> Evaluating ...')\n",
        "\n",
        "test('train')\n",
        "test('test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y75hzIOMOZe7",
        "outputId": "8ebe5593-9514-4311-949d-39beee40d234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 704/704 [00:18<00:00, 38.64it/s]\n"
          ]
        }
      ],
      "source": [
        "# Feature Extraction\n",
        "\n",
        "features1 = []\n",
        "features2 = []\n",
        "features3 = []\n",
        "features4 = []\n",
        "features5 = []\n",
        "labels_p = []\n",
        "\n",
        "def extract_features() :\n",
        "    model.eval() # Features are extracted in evaluation mode\n",
        "\n",
        "    with torch.no_grad() :\n",
        "        for inputs, targets in tqdm(train_loader):\n",
        "\n",
        "            inputs1 = inputs.to(device)\n",
        "            targets1 = targets.to(device)\n",
        "\n",
        "            x1 = model.layer1(inputs1)\n",
        "            x11= x1.view(x1.size(0), x1.size(1), -1)\n",
        "            size = x11.shape[2]\n",
        "            x11 = torch.div(torch.sum(x11, 2), size)\n",
        "            features1.extend(x11)\n",
        "\n",
        "            x2 = model.layer2(x1)\n",
        "            x22= x2.view(x2.size(0), x2.size(1), -1)\n",
        "            size = x22.shape[2]\n",
        "            x22 = torch.div(torch.sum(x22, 2), size)\n",
        "            features2.extend(x22)\n",
        "\n",
        "            x3 = model.layer3(x2)\n",
        "            x33= x3.view(x3.size(0), x3.size(1), -1)\n",
        "            size = x33.shape[2]\n",
        "            x33 = torch.div(torch.sum(x33, 2), size)\n",
        "            features3.extend(x33)\n",
        "\n",
        "            x4 = model.layer4(x3)\n",
        "            x44= x4.view(x4.size(0), x4.size(1), -1)\n",
        "            size = x44.shape[2]\n",
        "            x44 = torch.div(torch.sum(x44, 2), size)\n",
        "            features4.extend(x44)\n",
        "\n",
        "            x5 = model.layer5(x4)\n",
        "            x55 = x5.view(x5.size(0), x5.size(1), -1)\n",
        "            size = x55.shape[2]\n",
        "            x55 = torch.div(torch.sum(x55, 2), size)\n",
        "            features5.extend(x55)\n",
        "            \n",
        "            labels_p.extend(targets1)\n",
        "    return\n",
        "\n",
        "extract_features()\n",
        "features1 = torch.stack(features1)\n",
        "features2 = torch.stack(features2)\n",
        "features3 = torch.stack(features3)\n",
        "features4 = torch.stack(features4)\n",
        "features5 = torch.stack(features5)\n",
        "labels_p = torch.stack(labels_p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOq35CbLu-RZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "642f3a80-e828-4f38-f89e-6a6c6da8c95a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([89996, 64]), torch.Size([89996, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "features3.shape,labels_p.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SGrasolK4X1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8671174f-a809-4355-e352-59e58140d266"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "dump_at = '/content/drive/MyDrive/BTP/' + data_flag + '/'\n",
        "os.mkdir(dump_at)\n",
        "\n",
        "X = features1.cpu().detach().numpy() #convert to Numpy array\n",
        "df = pd.DataFrame(X) #convert to a dataframe\n",
        "df.to_csv(dump_at + \"L1_FeatureMap_avg.csv\",index=False) #save to file\n",
        "\n",
        "X = features2.cpu().detach().numpy() \n",
        "df = pd.DataFrame(X) \n",
        "df.to_csv(dump_at + \"L2_FeatureMap_avg.csv\",index=False) \n",
        "\n",
        "X = features3.cpu().detach().numpy() \n",
        "df = pd.DataFrame(X) \n",
        "df.to_csv(dump_at + \"L3_FeatureMap_avg.csv\",index=False) \n",
        "\n",
        "X = features4.cpu().detach().numpy() \n",
        "df = pd.DataFrame(X) \n",
        "df.to_csv(dump_at + \"L4_FeatureMap_avg.csv\",index=False) \n",
        "\n",
        "X = features5.cpu().detach().numpy() \n",
        "df = pd.DataFrame(X) \n",
        "df.to_csv(dump_at + \"L5_FeatureMap_avg.csv\",index=False) \n",
        "\n",
        "X = labels_p.cpu().detach().numpy() \n",
        "df = pd.DataFrame(X) \n",
        "df.to_csv(dump_at + \"labels.csv\",index=False) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YI7WWH6gcjKH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "dump_at = '/content/drive/MyDrive/BTP/' + data_flag + '/'\n",
        "# os.mkdir(dump_at)\n",
        "\n",
        "L1 = L1.cpu()\n",
        "L1_np = L1.detach().numpy() #convert to Numpy array\n",
        "L1_np = np.sum(L1_np, axis=-1)/L1_np.shape[2]\n",
        "df = pd.DataFrame(L1_np) #convert to a dataframe\n",
        "df.to_csv(dump_at + \"L1_FeatureMap_avg.csv\",index=False) #save to file\n",
        "\n",
        "L2 = L2.cpu()\n",
        "L2_np = L2.detach().numpy() \n",
        "L2_np = np.sum(L2_np, axis=-1)/L2_np.shape[2]\n",
        "df = pd.DataFrame(L2_np) \n",
        "df.to_csv(dump_at + \"L2_FeatureMap_avg.csv\",index=False) \n",
        "\n",
        "L3 = L3.cpu()\n",
        "L3_np = L3.detach().numpy()\n",
        "L3_np = np.sum(L3_np, axis=-1)/L3_np.shape[2]\n",
        "df = pd.DataFrame(L3_np) \n",
        "df.to_csv(dump_at + \"L3_FeatureMap_avg.csv\",index=False) \n",
        "\n",
        "L4 = L4.cpu()\n",
        "L4_np = L4.detach().numpy()\n",
        "L4_np = np.sum(L4_np, axis=-1)/L4_np.shape[2]\n",
        "df = pd.DataFrame(L4_np)\n",
        "df.to_csv(dump_at + \"L4_FeatureMap_avg.csv\",index=False) \n",
        "\n",
        "L5 = L5.cpu()\n",
        "L5_np = L5.detach().numpy() \n",
        "L5_np = np.sum(L5_np, axis=-1)/L5_np.shape[2]\n",
        "df = pd.DataFrame(L5_np) \n",
        "df.to_csv(dump_at + \"L5_FeatureMap_avg.csv\",index=False) \n",
        "\n",
        "t1 = t1.cpu()\n",
        "t1_np = t1.detach().numpy()\n",
        "df = pd.DataFrame(t1_np) \n",
        "df.to_csv(dump_at + \"labels.csv\",index=False) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MCSdEn7hE_M"
      },
      "outputs": [],
      "source": [
        "def write_features(n) :\n",
        "    L1 = torch.stack(features1)\n",
        "    L2 = torch.stack(features2)\n",
        "    L3 = torch.stack(features3)\n",
        "    L4 = torch.stack(features4)\n",
        "    L5 = torch.stack(features5)\n",
        "    t1 = torch.stack(labels_p)\n",
        "\n",
        "    dump_at = '/content/drive/MyDrive/BTP/' + data_flag + '/'\n",
        "\n",
        "    L1 = L1.cpu()\n",
        "    L1_np = L1.detach().numpy() #convert to Numpy array\n",
        "    L1_np = np.sum(L1_np, axis=-1)/L1_np.shape[2]\n",
        "    df = pd.DataFrame(L1_np) #convert to a dataframe\n",
        "    df.to_csv(dump_at + \"L1_FeatureMap_avg_%d.csv\"%(n),index=False) #save to file\n",
        "\n",
        "    L2 = L2.cpu()\n",
        "    L2_np = L2.detach().numpy() \n",
        "    L2_np = np.sum(L2_np, axis=-1)/L2_np.shape[2]\n",
        "    df = pd.DataFrame(L2_np) \n",
        "    df.to_csv(dump_at + \"L2_FeatureMap_avg_%d.csv\"%(n),index=False) \n",
        "\n",
        "    L3 = L3.cpu()\n",
        "    L3_np = L3.detach().numpy()\n",
        "    L3_np = np.sum(L3_np, axis=-1)/L3_np.shape[2]\n",
        "    df = pd.DataFrame(L3_np) \n",
        "    df.to_csv(dump_at + \"L3_FeatureMap_avg_%d.csv\"%(n),index=False) \n",
        "\n",
        "    L4 = L4.cpu()\n",
        "    L4_np = L4.detach().numpy()\n",
        "    L4_np = np.sum(L4_np, axis=-1)/L4_np.shape[2]\n",
        "    df = pd.DataFrame(L4_np)\n",
        "    df.to_csv(dump_at + \"L4_FeatureMap_avg_%d.csv\"%(n),index=False) \n",
        "\n",
        "    L5 = L5.cpu()\n",
        "    L5_np = L5.detach().numpy() \n",
        "    L5_np = np.sum(L5_np, axis=-1)/L5_np.shape[2]\n",
        "    df = pd.DataFrame(L5_np) \n",
        "    df.to_csv(dump_at + \"L5_FeatureMap_avg_%d.csv\"%(n),index=False) \n",
        "\n",
        "    t1 = t1.cpu()\n",
        "    t1_np = t1.detach().numpy()\n",
        "    df = pd.DataFrame(t1_np) \n",
        "    df.to_csv(dump_at + \"labels_%d.csv\"%(n),index=False) \n",
        "\n",
        "    return"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "interpreter": {
      "hash": "3c91f51d078f7a46d6d3d7490e4b8dcbd8f867564e34e2e66492434dd23701a4"
    },
    "kernelspec": {
      "display_name": "Python 3.6.13 ('myenv': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "231cb88ce25a45089090375095790f16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_171600feb07640718086820482ebda76",
              "IPY_MODEL_d2f05dfde85d42adb7d8e4edfee145d1",
              "IPY_MODEL_6ecafece7c4748ea97d2a4ffea9cb21e"
            ],
            "layout": "IPY_MODEL_f535159a00c3494aab4989eebb894024"
          }
        },
        "171600feb07640718086820482ebda76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05c33a505bce400182cac16b0ea25d41",
            "placeholder": "​",
            "style": "IPY_MODEL_a07222e0a31a44818196ea256ef67338",
            "value": "100%"
          }
        },
        "d2f05dfde85d42adb7d8e4edfee145d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd846d4d74d04dbaafa5f3f7bbbebd06",
            "max": 205615438,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ed160e8b9a542e2b01f11ce348ff649",
            "value": 205615438
          }
        },
        "6ecafece7c4748ea97d2a4ffea9cb21e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c00be766afe04ca495ddbce49132ff62",
            "placeholder": "​",
            "style": "IPY_MODEL_37f0bea3477141b892a1d58bd357b43a",
            "value": " 205615438/205615438 [00:25&lt;00:00, 13156218.17it/s]"
          }
        },
        "f535159a00c3494aab4989eebb894024": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05c33a505bce400182cac16b0ea25d41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a07222e0a31a44818196ea256ef67338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd846d4d74d04dbaafa5f3f7bbbebd06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ed160e8b9a542e2b01f11ce348ff649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c00be766afe04ca495ddbce49132ff62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37f0bea3477141b892a1d58bd357b43a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}